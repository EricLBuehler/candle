#include "../util.pwgsl"


override CONSTV_0 : bool = true;
override CONSTV_1 : bool = true;
override CONSTV_2 : bool = true;
override CONSTV_3 : bool = true;
override CONSTV_4 : bool = true;
override CONSTV_5 : u32 = 0u;


#define op_matmul_use_batch   CONSTV_4

#define op_matmul_b                 op_meta[0]
#define op_matmul_m                 op_meta[1]
#define op_matmul_k                 op_meta[2]
#define op_matmul_n                 op_meta[3]

#define op_matmul_input1_stride_b   op_meta[4]
#define op_matmul_input1_offset     op_meta[5]

#define op_matmul_input2_stride_b   op_meta[6]
#define op_matmul_input2_offset     op_meta[7]

#define op_matmul_is_input1_stride_k_one CONSTV_0
#define op_matmul_is_input1_stride_m_one CONSTV_1
#define op_matmul_is_input2_stride_n_one CONSTV_2
#define op_matmul_is_input2_stride_k_one CONSTV_3

#define op_matmul_input1_stride_k   select(op_matmul_is_input1_stride_k_one, 1u, op_meta[8])
#define op_matmul_input1_stride_m   select(op_matmul_is_input1_stride_m_one, 1u, op_meta[9]) 

#define op_matmul_input2_stride_n   select(op_matmul_is_input2_stride_n_one, 1u, op_meta[10])
#define op_matmul_input2_stride_k   select(op_matmul_is_input2_stride_k_one, 1u, op_meta[11])


#ifndef RTSM
#definec RTSM TSM/WPTM
#endif
#ifndef RTSN
#definec RTSN TSN/WPTN
#endif

#definec NEEDEDRTSM TSM/WPTM
#definec NEEDEDRTSN TSN/WPTN

#definec THREADS RTSM * RTSN
#definec LPTA (TSK*TSM)/THREADS
#definec LPTB (TSK*TSN)/THREADS

override IsOutputPadded : bool = false;

#assert (TSK*TSM)%(THREADS) == 0
#assert ((TSK*TSN)%(THREADS)) == 0
#assert RTSM > 0
#assert RTSN > 0
#assert TSM % WPTM == 0
#assert TSN % WPTN == 0


#ifndef WIDTHA
#define WIDTHA 4u
#endif

#ifndef WIDTHB
#define WIDTHB 4u
#endif



#if WIDTHA == 1
#define ARRAY_TYPEA array<DTYPE, 1>
#elif WIDTHA == 2
#define ARRAY_TYPEA vec2<DTYPE>
#elif WIDTHA == 4
#define ARRAY_TYPEA vec4<DTYPE>
#endif


#if WIDTHB == 1
#define ARRAY_TYPEB array<DTYPE, 1>
#elif WIDTHB == 2
#define ARRAY_TYPEB vec2<DTYPE>
#elif WIDTHB == 4
#define ARRAY_TYPEB vec4<DTYPE>
#endif



#assert (LPTA) % WIDTHA == 0
#assert (LPTB) % WIDTHB == 0


@group(0) @binding(2)
var<storage> v_input_a: array<ARRAY_TYPEA>;

@group(0) @binding(3)
var<storage> v_input_b: array<ARRAY_TYPEB>;



#ifdef PREFETCH
#define PREFETCH 2
#else
#define PREFETCH 1
#endif


#ifndef WONT_USE_LOADA
var<workgroup> Asub: array<array<array<DTYPE, TSM>, TSK>, PREFETCH>;
#endif

#ifndef WONT_USE_LOADB
var<workgroup> Bsub: array<array<array<DTYPE, TSN>, TSK>, PREFETCH>;
#endif

#definec LPTAWITDH LPTA / WIDTHA
#definec TSKAWIDTH TSK / WIDTHA
#definec TSMAWIDTH TSM / WIDTHA
#ifndef WONT_USE_LOADA
fn loadA(tile : u32, tid : u32, t_offset1 : u32){
    for(var la = 0u; la < LPTAWITDH; la += 1u){
        let id = la*THREADS + tid;
        if op_matmul_is_input1_stride_k_one{
            let id_k = id % TSKAWIDTH;
            let id_m = id / TSKAWIDTH;

            var vecA : ARRAY_TYPEA = v_input_a[t_offset1 + id_k * op_matmul_input1_stride_k + id_m * (op_matmul_input1_stride_m / WIDTHA)];
            for(var j = 0u; j < WIDTHA; j++){
                Asub[tile][WIDTHA * id_k + j][id_m] = vecA[j];
            }
        }
        else{
            let id_k = id / TSMAWIDTH;
            let id_m = id % TSMAWIDTH;

            var vecA : ARRAY_TYPEA = v_input_a[t_offset1 + id_k * (op_matmul_input1_stride_k / WIDTHA) + id_m * op_matmul_input1_stride_m];
            
            for(var j = 0u; j < WIDTHA; j++){
                Asub[tile][id_k][WIDTHA * id_m + j] = vecA[j];
            }
        }
    }
}
#endif



#definec LPTBWITDH LPTB / WIDTHB
#definec TSKBWIDTH TSK / WIDTHB
#definec TSNBWIDTH TSN / WIDTHB
#ifndef WONT_USE_LOADB
fn loadB(tile : u32, tid : u32, t_offset2 : u32){
    for(var lb = 0u; lb < LPTBWITDH; lb += 1u){
        let id = lb*THREADS + tid;

        if (op_matmul_is_input2_stride_k_one){
            let id_n = id / TSKBWIDTH;
            let id_k = id % TSKBWIDTH;

            var vecB : ARRAY_TYPEB = v_input_b[t_offset2 + id_k * op_matmul_input2_stride_k + id_n * (op_matmul_input2_stride_n / WIDTHB)];
            
            for(var j = 0u; j < WIDTHB; j++){
                Bsub[tile][WIDTHB * id_k + j][id_n] = vecB[j];
            }
        }
        else{
            let id_n = id % TSNBWIDTH;
            let id_k = id / TSNBWIDTH;

            var vecB : ARRAY_TYPEB = v_input_b[t_offset2 + id_k * (op_matmul_input2_stride_k/WIDTHB) + id_n * op_matmul_input2_stride_n];
            for(var j = 0u; j < WIDTHB; j++){
                Bsub[tile][id_k][WIDTHB * id_n + j] = vecB[j];
            }
        }
    }
}
#endif



#ifndef WONT_USE_LOADA
#define PreLoadA
#endif

#ifndef WONT_USE_LOADB
#define PreLoadB
#endif



fn load(tile : u32, tid : u32, t_offset1 : u32, t_offset2 : u32){
    #ifdef PreLoadA
        loadA(tile, tid, t_offset1);
    #endif
    #ifdef PreLoadB
        loadB(tile, tid, t_offset2);
    #endif
}


fn generic_sgemm(group_id: vec3<u32>, local_id: vec3<u32>) {
    let lx = local_id.x * WPTN;
    let ly = local_id.y * WPTM;

    let gx = TSN*group_id.x + lx;
    let gy = TSM*group_id.y + ly;

    let input1_stride_b = select(op_matmul_use_batch, op_matmul_input1_stride_b, 0u); 
    let input2_stride_b = select(op_matmul_use_batch, op_matmul_input2_stride_b, 0u); 

    let m_input1_offset = (op_matmul_input1_offset + op_matmul_input1_stride_m * TSM * group_id.y + group_id.z * input1_stride_b);
    let m_input2_offset = (op_matmul_input2_offset + op_matmul_input2_stride_n * TSN * group_id.x + group_id.z * input2_stride_b);

    let max_k = op_matmul_k;

    var a_reg = ZERO;
    var b_reg = array<DTYPE, WPTN>();
    var acc = array<array<DTYPE, WPTN>, WPTM>();

    let tid = local_id.y*RTSN + local_id.x;

    var tt = 0u;
    //use prefetch:
    #if PREFETCH == 2
        load(tt, tid, m_input1_offset/WIDTHA, m_input2_offset/WIDTHA);
        workgroupBarrier();
    #endif

    for(var t = 0u; t < max_k; ){
        //normal load
        #if PREFETCH != 2 
        {
            let t_offset1 = (m_input1_offset + t * op_matmul_input1_stride_k)/WIDTHA;   
            let t_offset2 = (m_input2_offset + t * op_matmul_input2_stride_k)/WIDTHB;
            load(0u, tid, t_offset1, t_offset2); //load the current Tile
            workgroupBarrier();
        }
        #endif

        #ifndef PreLoadA
        let t_offset1 = m_input1_offset + t * op_matmul_input1_stride_k;
        #endif

        #ifndef PreLoadB
        let t_offset2 = m_input2_offset + t * op_matmul_input2_stride_k;
        #endif


        #ifndef PreLoadB //we may load multiple k values
            if op_matmul_input2_stride_n != 1{
                var a_reg = array<DTYPE,WIDTHB>();
                for (var k=0u; k<TSK; k += WIDTHB) {

                    #ifdef PreLoadA
                        for (var wm=0u; wm<WPTM; wm++) {
                            for(var ki=0u; ki < WIDTHB; ki++){
                                a_reg[ki] = Asub[tt][k + ki][ly + wm];
                            }
                            for (var wn=0u; wn<WPTN; wn++) {
                                let id = t_offset2 + k * op_matmul_input2_stride_k + (lx + wn) * op_matmul_input2_stride_n;
                                var vecB : ARRAY_TYPEB = v_input_b[id / WIDTHB];
        
                                for(var ki=0u; ki < WIDTHB; ki++){
                                    acc[wm][wn] += a_reg[ki] * vecB[ki];
                                }
                            }
                        }
                    #else
                        #assert 0 == 1 //expect PreLoadA in this case
                    #endif
                }
            } 
            else{
        #endif       
        
   
        // Loop over the values of a single tile
        for (var k=0u; k<TSK; k++) {

            // Cache the values of Bsub in registers
            #ifdef PreLoadB
                for (var wn=0u; wn<WPTN; wn++) {
                    b_reg[wn] = Bsub[tt][k][lx + wn];
                }
            #else    
                #assert WPTN % WIDTHB == 0
                #definec WPTNBWIDTH WPTN / WIDTHB
                if op_matmul_input2_stride_n == 1{
                    for (var wn=0u; wn<WPTNBWIDTH; wn++) {
                        let id = t_offset2 + k * op_matmul_input2_stride_k + (lx + wn*WIDTHB) * op_matmul_input2_stride_n;
                        var vecB : ARRAY_TYPEB = v_input_b[id / WIDTHB];

                        for(var j = 0u; j < WIDTHB; j++){
                            b_reg[WIDTHB*wn + j] = vecB[j];
                        }
                    }
                }
            #endif

            // Perform the computation
            #ifdef PreLoadA
                for (var wm=0u; wm<WPTM; wm++) {
                    a_reg = Asub[tt][k][ly + wm];
                    for (var wn=0u; wn<WPTN; wn++) {
                        acc[wm][wn] += a_reg * b_reg[wn];
                    }
                }
            #else
                for (var wm=0u; wm<WPTM; wm++) {
                    let id = t_offset1 + k * op_matmul_input1_stride_k + (ly + wm) * op_matmul_input1_stride_m;
                    let vecA : ARRAY_TYPEA = v_input_a[id / WIDTHA];

                    #if WIDTHA == 1
                        a_reg = vecA;
                    #elif WIDTHA == 2
                        a_reg = vecA[id % WIDTHA];
                    #elif WIDTHA == 4
                        a_reg = vecA[id % WIDTHA];
                    #endif 

                    for (var wn=0u; wn<WPTN; wn++) {
                        acc[wm][wn] += a_reg * b_reg[wn];
                    }
                }    
            #endif
        }

        #ifndef PreLoadB //we may load multiple k values
            }
        #endif

        t +=TSK;

        #if PREFETCH == 2 //use prefetch:
        {
            tt = tt ^ 1;
            if (t < max_k){
                let t_offset1 = (m_input1_offset + t * op_matmul_input1_stride_k)/WIDTHA;
                let t_offset2 = (m_input2_offset + t * op_matmul_input2_stride_k)/WIDTHB;
                load(tt, tid, t_offset1, t_offset2); //load the next Tile
            }
        }
        #endif
        workgroupBarrier();
    }
   
    let dest_index = group_id.z * select(op_matmul_use_batch, op_matmul_m * op_matmul_n, 0u) + gy * op_matmul_n + gx;
    if IsOutputPadded{
        // let is_in_gy = gy < op_matmul_m;
        // let is_in_gx = gx < op_matmul_n;
        // let is_output_pixel = is_in_gy && is_in_gx;

        // let wcount_x = select(is_in_gx, min(op_matmul_n - gx, WPTN), 0u);
        // let wcount_y = select(is_in_gy, min(op_matmul_m - gy, WPTM), 0u);
        // if(is_output_pixel){
        //     if (wcount_y == WPTM && wcount_x == WPTN){
        //         for (var wm=0u; wm<WPTM; wm++) {
        //             let globalRow = dest_index + wm * op_matmul_n;
        //             for (var wn=0u; wn<WPTN; wn++) {
        //                 var globalCol = globalRow + wn;
        //                 v_dest[globalCol] = acc[wm][wn];
        //             }
        //         }
        //     }
        //     else{
        //         for (var wm=0u; wm< wcount_y; wm++) {
        //             let globalRow = dest_index + wm * op_matmul_n;
        //             for (var wn=0u; wn< wcount_x; wn++) {
        //                 var globalCol = globalRow + wn;
        //                 v_dest[globalCol] = acc[wm][wn];
        //             }
        //         }
        //     }
        // }
    }
    else{
        for (var wm=0u; wm<WPTM; wm++) {
            let globalRow = dest_index + wm * op_matmul_n;
            for (var wn=0u; wn<WPTN; wn++) {
                var globalCol = globalRow + wn;
                v_dest[globalCol] = acc[wm][wn];
            }
        }
    }
   
}

@compute @workgroup_size(RTSN, RTSM, 1)
//MxK * KxN = MxN
fn matmul(@builtin(workgroup_id) group_id: vec3<u32>, @builtin(local_invocation_id) local_id: vec3<u32>) {
    generic_sgemm(group_id, local_id);
}