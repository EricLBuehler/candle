// const TSM : u32 = 64u;                // The tile-size in dimension M
// const TSN : u32 = 64u;                // The tile-size in dimension N
// const TSK : u32 = 16u;                 // The tile-size in dimension K
// const WPTM : u32 = 8u;                 // The work-per-thread in dimension M
// const WPTN : u32 = 8u;                 // The work-per-thread in dimension N
// const PREFETCH : u32 = 1u; //no prefetch

#define TSM 64u                     // The tile-size in dimension M
#define TSN 64u                     // The tile-size in dimension N
#define TSK 16u                     // The tile-size in dimension K
//#define RTSM 16u                    //we use 16x16 threads for loading, but only a subpart of the threads will load 8x8 tiles
//#define RTSN 16u                    
#define WPTM 8u                     // The work-per-thread in dimension M
#define WPTN 4u                     // The work-per-thread in dimension N
#define PREFETCH 1u

#include "matmulHelper.pwgsl"

@compute @workgroup_size(RTSN, RTSM, 1)
//MxK * KxN = MxN
fn matmul(@builtin(workgroup_id) group_id: vec3<u32>, @builtin(local_invocation_id) local_id: vec3<u32>) {
    generic_sgemm(group_id, local_id);
}

@compute @workgroup_size(RTSN, RTSM, 1)
//MxK * KxN = MxN
fn matmul_no_padded(@builtin(workgroup_id) group_id: vec3<u32>, @builtin(local_invocation_id) local_id: vec3<u32>) {
    generic_sgemm(group_id, local_id);
    //generic_sgemm_no_padded(group_id, local_id);
}